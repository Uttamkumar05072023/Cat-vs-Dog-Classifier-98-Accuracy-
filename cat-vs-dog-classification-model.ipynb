{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat Vs Dog Classification Model From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T15:28:36.579971Z",
     "iopub.status.busy": "2025-08-25T15:28:36.579532Z",
     "iopub.status.idle": "2025-08-25T15:28:43.845000Z",
     "shell.execute_reply": "2025-08-25T15:28:43.844401Z",
     "shell.execute_reply.started": "2025-08-25T15:28:36.579946Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for CPU/GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T15:28:43.846965Z",
     "iopub.status.busy": "2025-08-25T15:28:43.846627Z",
     "iopub.status.idle": "2025-08-25T15:28:43.931790Z",
     "shell.execute_reply": "2025-08-25T15:28:43.930923Z",
     "shell.execute_reply.started": "2025-08-25T15:28:43.846947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformations for better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T15:28:43.933426Z",
     "iopub.status.busy": "2025-08-25T15:28:43.932707Z",
     "iopub.status.idle": "2025-08-25T15:28:43.975505Z",
     "shell.execute_reply": "2025-08-25T15:28:43.974511Z",
     "shell.execute_reply.started": "2025-08-25T15:28:43.933393Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T15:28:43.977003Z",
     "iopub.status.busy": "2025-08-25T15:28:43.976726Z",
     "iopub.status.idle": "2025-08-25T15:29:01.532467Z",
     "shell.execute_reply": "2025-08-25T15:29:01.531621Z",
     "shell.execute_reply.started": "2025-08-25T15:28:43.976978Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root=\"/kaggle/input/dogs-vs-cats/train\",transform=train_transform)\n",
    "test_data = datasets.ImageFolder(root=\"/kaggle/input/dogs-vs-cats/test\",transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T15:29:01.533632Z",
     "iopub.status.busy": "2025-08-25T15:29:01.533360Z",
     "iopub.status.idle": "2025-08-25T15:29:01.538562Z",
     "shell.execute_reply": "2025-08-25T15:29:01.537774Z",
     "shell.execute_reply.started": "2025-08-25T15:29:01.533606Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,batch_size=256,shuffle=True,pin_memory=True,num_workers=4,persistent_workers=True,prefetch_factor=4)\n",
    "test_loader = DataLoader(test_data,batch_size=256,shuffle=False,pin_memory=True,num_workers=4,persistent_workers=True,prefetch_factor=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T15:29:01.539715Z",
     "iopub.status.busy": "2025-08-25T15:29:01.539430Z",
     "iopub.status.idle": "2025-08-25T15:29:01.558924Z",
     "shell.execute_reply": "2025-08-25T15:29:01.558324Z",
     "shell.execute_reply.started": "2025-08-25T15:29:01.539687Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1):  # binary classification\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 112x112\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 56x56\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 28x28\n",
    "\n",
    "            # Block 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 14x14\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*14*14, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "            nn.Sigmoid()  # since BCELoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T15:29:01.559905Z",
     "iopub.status.busy": "2025-08-25T15:29:01.559712Z",
     "iopub.status.idle": "2025-08-25T15:29:02.100647Z",
     "shell.execute_reply": "2025-08-25T15:29:02.100015Z",
     "shell.execute_reply.started": "2025-08-25T15:29:01.559888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "lr = 1e-3\n",
    "model = CNNModel(3)\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\",torch.cuda.device_count(),\"GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T15:31:49.427398Z",
     "iopub.status.busy": "2025-08-25T15:31:49.426316Z",
     "iopub.status.idle": "2025-08-25T16:16:40.157868Z",
     "shell.execute_reply": "2025-08-25T16:16:40.157036Z",
     "shell.execute_reply.started": "2025-08-25T15:31:49.427327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.6233 | Val Loss: 0.6149\n",
      "Validation loss improved ✅ model saved\n",
      "Epoch 2/50 | Train Loss: 0.6108 | Val Loss: 0.6308\n",
      "No improvement for 1 epochs\n",
      "Epoch 3/50 | Train Loss: 0.5877 | Val Loss: 0.6270\n",
      "No improvement for 2 epochs\n",
      "Epoch 4/50 | Train Loss: 0.5769 | Val Loss: 0.5886\n",
      "Validation loss improved ✅ model saved\n",
      "Epoch 5/50 | Train Loss: 0.5611 | Val Loss: 0.5749\n",
      "Validation loss improved ✅ model saved\n",
      "Epoch 6/50 | Train Loss: 0.5442 | Val Loss: 0.5371\n",
      "Validation loss improved ✅ model saved\n",
      "Epoch 7/50 | Train Loss: 0.5171 | Val Loss: 0.5942\n",
      "No improvement for 1 epochs\n",
      "Epoch 8/50 | Train Loss: 0.5038 | Val Loss: 0.5628\n",
      "No improvement for 2 epochs\n",
      "Epoch 9/50 | Train Loss: 0.4816 | Val Loss: 0.8267\n",
      "No improvement for 3 epochs\n",
      "Epoch 10/50 | Train Loss: 0.4525 | Val Loss: 0.5973\n",
      "No improvement for 4 epochs\n",
      "Epoch 11/50 | Train Loss: 0.4259 | Val Loss: 0.4717\n",
      "Validation loss improved ✅ model saved\n",
      "Epoch 12/50 | Train Loss: 0.4176 | Val Loss: 0.8006\n",
      "No improvement for 1 epochs\n",
      "Epoch 13/50 | Train Loss: 0.3946 | Val Loss: 0.5022\n",
      "No improvement for 2 epochs\n",
      "Epoch 14/50 | Train Loss: 0.3765 | Val Loss: 0.3909\n",
      "Validation loss improved ✅ model saved\n",
      "Epoch 15/50 | Train Loss: 0.3633 | Val Loss: 0.3566\n",
      "Validation loss improved ✅ model saved\n",
      "Epoch 16/50 | Train Loss: 0.3303 | Val Loss: 0.7476\n",
      "No improvement for 1 epochs\n",
      "Epoch 17/50 | Train Loss: 0.3391 | Val Loss: 0.3252\n",
      "Validation loss improved ✅ model saved\n",
      "Epoch 18/50 | Train Loss: 0.3119 | Val Loss: 0.4438\n",
      "No improvement for 1 epochs\n",
      "Epoch 19/50 | Train Loss: 0.3100 | Val Loss: 0.3890\n",
      "No improvement for 2 epochs\n",
      "Epoch 20/50 | Train Loss: 0.3081 | Val Loss: 0.3269\n",
      "No improvement for 3 epochs\n",
      "Epoch 21/50 | Train Loss: 0.3002 | Val Loss: 0.2876\n",
      "Validation loss improved ✅ model saved\n",
      "Epoch 22/50 | Train Loss: 0.2770 | Val Loss: 0.3202\n",
      "No improvement for 1 epochs\n",
      "Epoch 23/50 | Train Loss: 0.2760 | Val Loss: 0.3993\n",
      "No improvement for 2 epochs\n",
      "Epoch 24/50 | Train Loss: 0.2797 | Val Loss: 0.3193\n",
      "No improvement for 3 epochs\n",
      "Epoch 25/50 | Train Loss: 0.2628 | Val Loss: 0.3247\n",
      "No improvement for 4 epochs\n",
      "Epoch 26/50 | Train Loss: 0.2654 | Val Loss: 0.3170\n",
      "No improvement for 5 epochs\n",
      "Early stopping triggered 🚨\n",
      "Training complete. Best Val Loss: 0.2876143239438534\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "patience = 5   # stop after 5 epochs with no improvement\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_epoch_loss = 0\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_epoch_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_epoch_loss / len(train_loader)\n",
    "\n",
    "    # ---- Validation Loop ----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # ---- Early Stopping Check ----\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "        print(\"Validation loss improved ✅ model saved\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epochs\")\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered 🚨\")\n",
    "        break\n",
    "\n",
    "# restore best weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(\"Training complete. Best Val Loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T16:16:40.159661Z",
     "iopub.status.busy": "2025-08-25T16:16:40.159426Z",
     "iopub.status.idle": "2025-08-25T16:16:59.503488Z",
     "shell.execute_reply": "2025-08-25T16:16:59.502591Z",
     "shell.execute_reply.started": "2025-08-25T16:16:40.159644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8594\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total,correct = 0,0\n",
    "with torch.no_grad():\n",
    "    for images,labels in test_loader:\n",
    "        images,labels = images.to(device,non_blocking=True),labels.to(device,non_blocking=True)\n",
    "        outputs = model(images)\n",
    "        preds = (outputs > 0.5).long()  # threshold for binary\n",
    "        correct += (preds.squeeze() == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "print(\"Testing accuracy:\",correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T16:16:59.504464Z",
     "iopub.status.busy": "2025-08-25T16:16:59.504245Z",
     "iopub.status.idle": "2025-08-25T16:18:14.029349Z",
     "shell.execute_reply": "2025-08-25T16:18:14.028619Z",
     "shell.execute_reply.started": "2025-08-25T16:16:59.504447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.86815\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total,correct = 0,0\n",
    "with torch.no_grad():\n",
    "    for images,labels in train_loader:\n",
    "        images,labels = images.to(device,non_blocking=True),labels.to(device,non_blocking=True)\n",
    "        outputs = model(images)\n",
    "        preds = (outputs > 0.5).long()  # threshold for binary\n",
    "        correct += (preds.squeeze() == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "print(\"Training accuracy:\",correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model with torchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T16:18:14.031166Z",
     "iopub.status.busy": "2025-08-25T16:18:14.030875Z",
     "iopub.status.idle": "2025-08-25T16:18:14.522565Z",
     "shell.execute_reply": "2025-08-25T16:18:14.521865Z",
     "shell.execute_reply.started": "2025-08-25T16:18:14.031146Z"
    }
   },
   "outputs": [],
   "source": [
    "if isinstance(model,torch.nn.DataParallel):\n",
    "    model = model.module  # unwrap to the original model\n",
    "m = torch.jit.script(model)\n",
    "m.save(\"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using transfer learning for improving accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:14:29.771858Z",
     "iopub.status.busy": "2025-08-25T17:14:29.771558Z",
     "iopub.status.idle": "2025-08-25T17:14:36.596546Z",
     "shell.execute_reply": "2025-08-25T17:14:36.595832Z",
     "shell.execute_reply.started": "2025-08-25T17:14:29.771835Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:14:36.598045Z",
     "iopub.status.busy": "2025-08-25T17:14:36.597664Z",
     "iopub.status.idle": "2025-08-25T17:14:36.674188Z",
     "shell.execute_reply": "2025-08-25T17:14:36.673437Z",
     "shell.execute_reply.started": "2025-08-25T17:14:36.598018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:14:40.338609Z",
     "iopub.status.busy": "2025-08-25T17:14:40.338032Z",
     "iopub.status.idle": "2025-08-25T17:14:40.343252Z",
     "shell.execute_reply": "2025-08-25T17:14:40.342504Z",
     "shell.execute_reply.started": "2025-08-25T17:14:40.338572Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:14:47.933763Z",
     "iopub.status.busy": "2025-08-25T17:14:47.933146Z",
     "iopub.status.idle": "2025-08-25T17:15:01.377979Z",
     "shell.execute_reply": "2025-08-25T17:15:01.377203Z",
     "shell.execute_reply.started": "2025-08-25T17:14:47.933737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "train_data = datasets.ImageFolder(root=\"/kaggle/input/dogs-vs-cats/train\",transform=train_transform)\n",
    "test_data = datasets.ImageFolder(root=\"/kaggle/input/dogs-vs-cats/test\",transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:15:16.126801Z",
     "iopub.status.busy": "2025-08-25T17:15:16.126116Z",
     "iopub.status.idle": "2025-08-25T17:15:16.130562Z",
     "shell.execute_reply": "2025-08-25T17:15:16.129882Z",
     "shell.execute_reply.started": "2025-08-25T17:15:16.126775Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,batch_size=128,shuffle=True,pin_memory=True,num_workers=4,persistent_workers=True,prefetch_factor=4)\n",
    "test_loader = DataLoader(test_data,batch_size=128,shuffle=False,pin_memory=True,num_workers=4,persistent_workers=True,prefetch_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:15:20.354283Z",
     "iopub.status.busy": "2025-08-25T17:15:20.354049Z",
     "iopub.status.idle": "2025-08-25T17:15:21.253788Z",
     "shell.execute_reply": "2025-08-25T17:15:21.253066Z",
     "shell.execute_reply.started": "2025-08-25T17:15:20.354265Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 90.0MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:15:35.170566Z",
     "iopub.status.busy": "2025-08-25T17:15:35.169944Z",
     "iopub.status.idle": "2025-08-25T17:15:35.174157Z",
     "shell.execute_reply": "2025-08-25T17:15:35.173526Z",
     "shell.execute_reply.started": "2025-08-25T17:15:35.170539Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:15:38.402765Z",
     "iopub.status.busy": "2025-08-25T17:15:38.402427Z",
     "iopub.status.idle": "2025-08-25T17:15:38.408371Z",
     "shell.execute_reply": "2025-08-25T17:15:38.407554Z",
     "shell.execute_reply.started": "2025-08-25T17:15:38.402742Z"
    }
   },
   "outputs": [],
   "source": [
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:15:42.410118Z",
     "iopub.status.busy": "2025-08-25T17:15:42.409498Z",
     "iopub.status.idle": "2025-08-25T17:15:42.415158Z",
     "shell.execute_reply": "2025-08-25T17:15:42.414543Z",
     "shell.execute_reply.started": "2025-08-25T17:15:42.410093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:16:04.962967Z",
     "iopub.status.busy": "2025-08-25T17:16:04.962693Z",
     "iopub.status.idle": "2025-08-25T17:16:04.966935Z",
     "shell.execute_reply": "2025-08-25T17:16:04.966258Z",
     "shell.execute_reply.started": "2025-08-25T17:16:04.962949Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:16:32.538370Z",
     "iopub.status.busy": "2025-08-25T17:16:32.538123Z",
     "iopub.status.idle": "2025-08-25T17:16:32.744214Z",
     "shell.execute_reply": "2025-08-25T17:16:32.743578Z",
     "shell.execute_reply.started": "2025-08-25T17:16:32.538353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count()>1:\n",
    "    print(\"Using\",torch.cuda.device_count(),\"GPUs\")\n",
    "    resnet18 = nn.DataParallel(resnet18)\n",
    "resnet18 = resnet18.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:17:42.956629Z",
     "iopub.status.busy": "2025-08-25T17:17:42.956085Z",
     "iopub.status.idle": "2025-08-25T17:24:10.444842Z",
     "shell.execute_reply": "2025-08-25T17:24:10.444198Z",
     "shell.execute_reply.started": "2025-08-25T17:17:42.956579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1660\n",
      "Epoch [2/10], Loss: 0.0841\n",
      "Epoch [3/10], Loss: 0.0723\n",
      "Epoch [4/10], Loss: 0.0711\n",
      "Epoch [5/10], Loss: 0.0651\n",
      "Epoch [6/10], Loss: 0.0638\n",
      "Epoch [7/10], Loss: 0.0651\n",
      "Epoch [8/10], Loss: 0.0625\n",
      "Epoch [9/10], Loss: 0.0596\n",
      "Epoch [10/10], Loss: 0.0603\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    resnet18.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device,non_blocking=True), labels.to(device,non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet18(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss/len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:26:39.395173Z",
     "iopub.status.busy": "2025-08-25T17:26:39.394728Z",
     "iopub.status.idle": "2025-08-25T17:26:51.944886Z",
     "shell.execute_reply": "2025-08-25T17:26:51.944117Z",
     "shell.execute_reply.started": "2025-08-25T17:26:39.395121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "resnet18.eval()\n",
    "total,correct = 0,0\n",
    "with torch.no_grad():\n",
    "    for images,labels in test_loader:\n",
    "        images,labels = images.to(device,non_blocking=True),labels.to(device,non_blocking=True)\n",
    "        outputs = resnet18(images)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "print(\"Testing accuracy:\",correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:27:23.202642Z",
     "iopub.status.busy": "2025-08-25T17:27:23.201959Z",
     "iopub.status.idle": "2025-08-25T17:27:59.779776Z",
     "shell.execute_reply": "2025-08-25T17:27:59.779085Z",
     "shell.execute_reply.started": "2025-08-25T17:27:23.202614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.98255\n"
     ]
    }
   ],
   "source": [
    "resnet18.eval()\n",
    "total,correct = 0,0\n",
    "with torch.no_grad():\n",
    "    for images,labels in train_loader:\n",
    "        images,labels = images.to(device,non_blocking=True),labels.to(device,non_blocking=True)\n",
    "        outputs = resnet18(images)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "print(\"Training accuracy:\",correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model with torchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:28:38.672994Z",
     "iopub.status.busy": "2025-08-25T17:28:38.672275Z",
     "iopub.status.idle": "2025-08-25T17:28:38.987975Z",
     "shell.execute_reply": "2025-08-25T17:28:38.987298Z",
     "shell.execute_reply.started": "2025-08-25T17:28:38.672968Z"
    }
   },
   "outputs": [],
   "source": [
    "if isinstance(resnet18,torch.nn.DataParallel):\n",
    "    resnet18 = resnet18.module  # unwrap to the original model\n",
    "m = torch.jit.script(resnet18)\n",
    "m.save(\"cat_vs_dog_using_resnet18.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T17:34:46.058650Z",
     "iopub.status.busy": "2025-08-25T17:34:46.058354Z",
     "iopub.status.idle": "2025-08-25T17:34:46.086655Z",
     "shell.execute_reply": "2025-08-25T17:34:46.086021Z",
     "shell.execute_reply.started": "2025-08-25T17:34:46.058626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw outputs: tensor([[ 2.3434, -4.2085]], device='cuda:0')\n",
      "Predicted class: cats\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "resnet18.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "img_path = \"/kaggle/input/dogs-vs-cats/train/cats/cat.11712.jpg\"\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "image = transform(image).unsqueeze(0)  # add batch dimension [1, C, H, W]\n",
    "image = image.to(device)\n",
    "classes = train_data.classes\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = resnet18(image)\n",
    "    print(\"Raw outputs:\", outputs)\n",
    "\n",
    "    preds = torch.argmax(outputs,1)\n",
    "    print(\"Predicted class:\",classes[preds.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 84954,
     "sourceId": 196452,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
